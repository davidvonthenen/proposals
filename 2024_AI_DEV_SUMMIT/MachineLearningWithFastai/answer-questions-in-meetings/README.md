# Answering Questions using a Voice Assistant using an LLM (answer-questions-in-meetings)

This uses Deepgram's Speech-to-Text (STT) to use the generated NLP model to listen for questions. When a question is detected, we send the question off to OpenAI's ChatGPT to find an answer to the question. That text based answer is then feedback into Deepgram's Text-to-Speech to turn the text into audio; thereby, giving our Assistant a voice.

## Prerequisites

Have only tested on MacOS, but should also work on most favors of Linux.

Using:

- Python 3.10+

I would highly recommend using something like:

- conda - <https://docs.anaconda.com/free/miniconda/>
- venv - <https://docs.python.org/3/library/venv.html>


## Installation

Install the required packages by running in your (virtual) environment:

```bash
pip install -r requirements.txt
```

## Running the Example

> If you don't have a crazy GPU, this could take some time. If you want to reduce the time and possibly reduce the accuracy, take a look at the comments in the code to make these modifications.

To run the example:

```bash
PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 PYTORCH_ENABLE_MPS_FALLBACK=1 python main.py
```

## To Clean Up

This will delete EVERYTHING that was downloaded or anything (like the model itself) generated by the script.

```bash
./clean.sh
```
