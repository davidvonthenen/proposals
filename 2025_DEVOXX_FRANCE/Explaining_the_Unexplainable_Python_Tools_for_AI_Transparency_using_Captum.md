**Talk Title:**  
Explaining the Unexplainable: Python Tools for AI Transparency using Captum

**Talk Abstract:**  
Artificial Intelligence often operates as a “black box,” leaving developers and stakeholders unsure how decisions are made. Explainable AI (XAI) addresses this challenge by providing tools to interpret and visualize AI model behavior, helping to build trust and transparency in AI systems. This session will focus on Captum, one of the leading Python libraries that makes black-box models interpretable.

Attendees will explore the fundamentals of XAI, learn how to integrate these libraries into their workflows, and discover techniques for generating feature attributions, decision-path visualizations, and scenario-specific insights. By the end of the session, participants will be equipped to apply XAI techniques to their own projects, gaining actionable insights into model behavior. A live demo will showcase the application of Captum to a trained model, providing clarity on how to debug, explain, and optimize real-world AI systems.

**Theme:**  
Data & AI

**Talk Session Type/Length:**  
45 minute breakout session

**Language:**  
English

**Select a difficulty:**  
Intermediate

**Elevator Pitch:**  
This session addresses a critical challenge in AI adoption: trust and transparency. By equipping attendees with practical tools and techniques, it bridges the gap between AI complexity and human interpretability. The inclusion of live demos ensures attendees leave with actionable knowledge to apply XAI principles using Python tools in their projects, making it a valuable addition to the Devoxx community.

**Slide Link:**  
TBD

**Video Link:**  
https://www.youtube.com/watch?v=YgeinCCUBCk&list=PLbt-vfK614XogHSmJ0CNmUXtaUKYM247t
