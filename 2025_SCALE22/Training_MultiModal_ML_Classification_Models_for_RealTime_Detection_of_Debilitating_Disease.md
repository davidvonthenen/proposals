**Title:**  
Training Multi-Modal ML Classification Models for Real-Time Detection of Debilitating Disease

**Audience:**  
Developer

**Topic:**  
Open Source AI and Applied Science

**Tags:**  
Medical Analysis, PyTorch, Pandas, NumPy, RealTime

**Appropriate for:**  
All ages

**Name:**  
Nikki-Rae Alkema
David vonThenen

**Primary contact email address:**  
davidvonthenen@gmail.com

**Brief Description:**  
Deconstructing the process of training Multi-modal (real-time video and audio) machine learning models to classify medical diseases

**Short Abstract:**  
This session breaks down the training process of multi-modal machine learning models for real-time detection of debilitating diseases using video and audio data. Attendees will learn how to build and integrate video and audio classifiers, curate multi-modal datasets, and deploy these models in real-world settings. The session includes practical demonstrations and code samples to help participants implement their own multi-modal classification models, equipping them with tools and methodologies to apply in the healthcare industry or other fields requiring complex real-time detection.

**Long Description:**  
Multi-modal machine learning (ML) is revolutionizing the healthcare industry by enabling real-time disease detection through simultaneous video and audio data analysis. This session will walk attendees through the complete process of developing classification models that combine video and audio inputs to detect early signs of debilitating diseases. By deconstructing the model-building process, weâ€™ll explore how to curate and preprocess multi-modal datasets, select appropriate model architectures, and effectively train models that can analyze complex medical data in real time.

The session goes beyond theory with practical, hands-on guidance for building these models. Attendees will gain insights into creating video and audio classifiers from scratch and learn how to fuse these models for more accurate, real-time predictions. We will also demonstrate how to deploy these models in a live setting, showing how real-time classification can be achieved. Participants will leave with working code, a clear methodology for approaching multi-modal ML problems, and a roadmap to build models for healthcare or other domains requiring multi-modal analysis.

**Message to the reviewers:**  
This session provides attendees with a comprehensive, step-by-step approach to building multi-modal ML classification models, focusing on real-time disease detection. Attendees will walk away with knowledge, practical skills, and working code for constructing and deploying these models. The inclusion of live demos and working code recipes sets this session apart, offering real-world application and immediate takeaways for participants. This session is not just about learning theory but about gaining actionable insights and tools that will enable attendees to apply multi-modal ML models in healthcare or other high-impact industries.